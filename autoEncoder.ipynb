{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "###### using http://www.easy-tensorflow.com/autoencoders/noise-removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/esadrfa/libs/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy.sparse as ss\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = ss.random(1000, 23000000, density=0.003, \n",
    "#                  format='csr', dtype=np.float32, random_state=10)\n",
    "data = ss.random(4, 5, density=0.7, \n",
    "                 format='csr', dtype=np.float32, random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyper-parameters\n",
    "logs_path = \"./logs/noiseRemoval_test_csr_matrix\"  # path to the folder that we want to save the logs for Tensorboard\n",
    "learning_rate = 0.001  # The optimization learning rate\n",
    "epochs = 10  # Total number of training epochs\n",
    "batch_size = 100  # Training batch size\n",
    "display_freq = 100  # Frequency of displaying the training results\n",
    "\n",
    "# Network Parameters\n",
    "num_features = data.shape[1]\n",
    "\n",
    "# number of units in the hidden layer\n",
    "# h1 = 1000\n",
    "h1 = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "coo_matrix = data.T.tocoo()\n",
    "tf_coo_matrix = tf.SparseTensorValue(\n",
    "    indices=np.array([coo_matrix.row, coo_matrix.col], dtype=np.int).T,\n",
    "    values=coo_matrix.data,\n",
    "    dense_shape=coo_matrix.shape)\n",
    "\n",
    "X = tf.SparseTensor.from_value(tf_coo_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(5), Dimension(4)])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.get_shape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'SparseTensor_3/values:0' shape=(14,) dtype=float32>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_original = tf.sparse_placeholder(tf.float32\\\n",
    "                           , shape=[batch_size, num_features]\\\n",
    "                           , name='X_original')\n",
    "\n",
    "# W = weight_variable(name, shape=[in_dim, num_units])\n",
    "initer = tf.truncated_normal_initializer(stddev=0.01)\n",
    "W = tf.get_variable('Weights_test', dtype=tf.float32, \n",
    "                    shape=[h1, num_features], initializer=initer)\n",
    "\n",
    "# b = bias_variable(name, [num_units])\n",
    "initial = tf.constant(0., shape=[h1,1], dtype=tf.float32)\n",
    "b = tf.get_variable('bias_test', dtype=tf.float32, initializer=initial)\n",
    "\n",
    "#         layer = tf.matmul(x, W)    #replaced with a sparse version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dimensions\n",
    "##### W:    n_h x n_f ==> 2 x 5 (num_hidden x num_features)\n",
    "##### X:     n_f x n_d ==> 5 x 4 (num_features x num_data_points)\n",
    "##### b:     n_h x 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Tensor(\"Weights_test:0\", shape=(2, 5), dtype=float32_ref) must be from the same graph as Tensor(\"SparseTensor_2/indices:0\", shape=(14, 2), dtype=int64).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-5f745820c123>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlayer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparse_tensor_dense_matmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainData\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mW\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/libs/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/sparse_ops.py\u001b[0m in \u001b[0;36msparse_tensor_dense_matmul\u001b[0;34m(sp_a, b, adjoint_a, adjoint_b, name)\u001b[0m\n\u001b[1;32m   1827\u001b[0m   \u001b[0msp_a\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_convert_to_sparse_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msp_a\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1828\u001b[0m   with ops.name_scope(name, \"SparseTensorDenseMatMul\",\n\u001b[0;32m-> 1829\u001b[0;31m                       [sp_a.indices, sp_a.values, b]) as name:\n\u001b[0m\u001b[1;32m   1830\u001b[0m     \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"b\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1831\u001b[0m     return gen_sparse_ops.sparse_tensor_dense_mat_mul(\n",
      "\u001b[0;32m~/libs/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   5768\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5769\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5770\u001b[0;31m       \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_graph_from_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5771\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_g_manager\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5772\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_g_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__enter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/libs/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_get_graph_from_inputs\u001b[0;34m(op_input_list, graph)\u001b[0m\n\u001b[1;32m   5428\u001b[0m         \u001b[0mgraph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_element\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5429\u001b[0m       \u001b[0;32melif\u001b[0m \u001b[0moriginal_graph_element\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5430\u001b[0;31m         \u001b[0m_assert_same_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moriginal_graph_element\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgraph_element\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5431\u001b[0m       \u001b[0;32melif\u001b[0m \u001b[0mgraph_element\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5432\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%s is not from the passed-in graph.\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mgraph_element\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/libs/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_assert_same_graph\u001b[0;34m(original_item, item)\u001b[0m\n\u001b[1;32m   5364\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0moriginal_item\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5365\u001b[0m     raise ValueError(\"%s must be from the same graph as %s.\" % (item,\n\u001b[0;32m-> 5366\u001b[0;31m                                                                 original_item))\n\u001b[0m\u001b[1;32m   5367\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5368\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Tensor(\"Weights_test:0\", shape=(2, 5), dtype=float32_ref) must be from the same graph as Tensor(\"SparseTensor_2/indices:0\", shape=(14, 2), dtype=int64)."
     ]
    }
   ],
   "source": [
    "layer = tf.sparse_tensor_dense_matmul(trainData, W)\n",
    "layer += b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sess = tf.InteractiveSession()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "out_values = fc_layer(trainData, num_features, h1, 'TestMatMult', use_relu=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# weight and bais wrappers\n",
    "def weight_variable(name, shape):\n",
    "    \"\"\"\n",
    "    Create a weight variable with appropriate initialization\n",
    "    :param name: weight name\n",
    "    :param shape: weight shape\n",
    "    :return: initialized weight variable\n",
    "    \"\"\"\n",
    "    initer = tf.truncated_normal_initializer(stddev=0.01)\n",
    "    return tf.get_variable('W_' + name,\n",
    "                           dtype=tf.float32,\n",
    "                           shape=shape,\n",
    "                           initializer=initer)\n",
    "\n",
    "def bias_variable(name, shape):\n",
    "    \"\"\"\n",
    "    Create a bias variable with appropriate initialization\n",
    "    :param name: bias variable name\n",
    "    :param shape: bias variable shape\n",
    "    :return: initialized bias variable\n",
    "    \"\"\"\n",
    "    initial = tf.constant(0., shape=shape, dtype=tf.float32)\n",
    "    return tf.get_variable('b_' + name,\n",
    "                           dtype=tf.float32,\n",
    "                           initializer=initial)\n",
    "\n",
    "def fc_layer(x, input_dim, num_units, name, use_relu=True):\n",
    "    \"\"\"\n",
    "    Create a fully-connected layer\n",
    "    :param x: input from previous layer\n",
    "    :param num_units: number of hidden units in the fully-connected layer\n",
    "    :param name: layer name\n",
    "    :param use_relu: boolean to add ReLU non-linearity (or not)\n",
    "    :return: The output array\n",
    "    \"\"\"\n",
    "    with tf.variable_scope(name):\n",
    "#         in_dim = x.get_shape()[1] \n",
    "        in_dim = input_dim\n",
    "        W = weight_variable(name, shape=[in_dim, num_units])\n",
    "        tf.summary.histogram('W', W)\n",
    "        b = bias_variable(name, [num_units])\n",
    "        tf.summary.histogram('b', b)\n",
    "#         layer = tf.matmul(x, W)    #replaced with a sparse version\n",
    "        layer = tf.sparse_tensor_dense_matmul(x, W)\n",
    "        layer += b\n",
    "        if use_relu:\n",
    "            layer = tf.nn.relu(layer)\n",
    "#         return tf.contrib.layers.dense_to_sparse(layer)\n",
    "    zero = tf.constant(0, dtype=tf.float32)\n",
    "    where = tf.not_equal(layer, zero)\n",
    "    indices = tf.where(where)\n",
    "    values = tf.gather_nd(layer, indices)\n",
    "    return tf.SparseTensor(indices, values, layer.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The below code allow to reset the graph and modify the layers, in case they  have already configured"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The error for not setting the first dimension on the sparse_placeholder\n",
    "<pre><code>\n",
    "Code:\n",
    "x_original = tf.sparse_placeholder(tf.float32, shape=[None, num_features]\\\n",
    "                           , name='X_original')\n",
    "Error:\n",
    "ValueError: Cannot convert a partially known TensorShape to a Tensor: (?, 5)\n",
    "</code></pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # sparse version\n",
    "# # Create graph\n",
    "# # Placeholders for inputs (x), outputs(y)\n",
    "# with tf.variable_scope('Input'):\n",
    "#     x_original = tf.sparse_placeholder(tf.float32\\\n",
    "#                            , shape=[batch_size, num_features]\\\n",
    "#                            , name='X_original')\n",
    "#     out_values = tf.sparse_placeholder(tf.float32\\\n",
    "#                            , shape=[batch_size, num_features]\\\n",
    "#                            , name='out_values')\n",
    "\n",
    "# fc1 = fc_layer(x_original, num_features, h1, 'Hidden_layer', use_relu=True)\n",
    "# out = fc_layer(fc1, h1, num_features, 'Output_layer', use_relu=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dense version\n",
    "# # Create graph\n",
    "# # Placeholders for inputs (x), outputs(y)\n",
    "# with tf.variable_scope('Input'):\n",
    "#     x_original = tf.placeholder(tf.float32\\\n",
    "#                            , shape=[batch_size, num_features]\\\n",
    "#                            , name='X_original')\n",
    "#     out_values = tf.placeholder(tf.float32\\\n",
    "#                            , shape=[batch_size, num_features]\\\n",
    "#                            , name='out_values')\n",
    "\n",
    "# fc1 = fc_layer(x_original, num_features, h1, 'Hidden_layer', use_relu=True)\n",
    "# out = fc_layer(fc1, h1, num_features, 'Output_layer', use_relu=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sparse version\n",
    "# Create graph\n",
    "# Placeholders for inputs (x), outputs(y)\n",
    "with tf.variable_scope('Input'):\n",
    "    x_original = tf.sparse_placeholder(tf.float32\\\n",
    "                           , shape=[batch_size, num_features]\\\n",
    "                           , name='X_original')\n",
    "#     out_values = tf.sparse_placeholder(tf.float32\\\n",
    "#                            , shape=[batch_size, num_features]\\\n",
    "#                            , name='out_values')\n",
    "\n",
    "    \n",
    "\n",
    "fc1 = fc_layer(x_original, num_features, h1, 'Hidden_layer', use_relu=True)\n",
    "# out = fc_layer(fc1, h1, num_features, 'Output_layer', use_relu=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### make_negative sparseTensor\n",
    "\n",
    "https://stackoverflow.com/a/40666375/2674061\n",
    "<pre><code>\n",
    "out.get_shape().as_list()[0]\n",
    "neg_eye = tf.scalar_mul(-1, tf.eye(out.get_shape().as_list()[1]))\n",
    "negative_val = tf.sparse_tensor_dense_matmul(out, neg_eye)     \n",
    "diff_sparsetensor = tf.sparse_add(x_original , negative_val)\n",
    "square_diff = tf.square(diff_sparsetensor)\n",
    "</code></pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define the loss function, optimizer, and accuracy for sparseTensors\n",
    "# with tf.variable_scope('Train'):\n",
    "#     with tf.variable_scope('Loss'):\n",
    "# #         loss = tf.sparse_reduce_sum_sparse(tf.losses.sparse_softmax_cross_entropy(x_original, out), name='loss')\n",
    "#         neg_eye = tf.scalar_mul(-1, tf.eye(out.get_shape().as_list()[1]))\n",
    "#         negative_val = tf.sparse_tensor_dense_matmul(out, neg_eye)     \n",
    "#         square_diff = tf.square(tf.sparse_add(x_original , negative_val))\n",
    "#         loss = tf.reduce_mean(square_diff, name='loss')\n",
    "#         tf.summary.scalar('loss', loss)\n",
    "#     with tf.variable_scope('Optimizer'):\n",
    "#         optimizer = tf.train.AdamOptimizer(\\\n",
    "#             learning_rate=learning_rate, \n",
    "#             name='Adam-op').minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_values = tf.placeholder(tf.float32, name='out_values')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coo_matrix = data.tocoo()\n",
    "tf_coo_matrix = tf.SparseTensorValue(\n",
    "    indices=np.array([coo_matrix.row, coo_matrix.col], dtype=np.int).T,\n",
    "    values=coo_matrix.data,\n",
    "    dense_shape=coo_matrix.shape)\n",
    "\n",
    "trainData = tf.SparseTensor.from_value(tf_coo_matrix)\n",
    "\n",
    "sess = tf.InteractiveSession()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "out_values = fc_layer(trainData, num_features, h1, 'TestMatMult', use_relu=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.run(out_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the loss function, optimizer, and accuracy for tensor (dense tensor)\n",
    "# with tf.variable_scope('Train'):\n",
    "#     with tf.variable_scope('Loss'):\n",
    "#         loss = tf.reduce_mean(tf.losses.mean_squared_error(x_original, out), name='loss')\n",
    "#         tf.summary.scalar('loss', loss)\n",
    "#     with tf.variable_scope('Optimizer'):\n",
    "#         optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate, name='Adam-op').minimize(loss)\n",
    "\n",
    "# # Initializing the variables\n",
    "# init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# return  SparseTensor\n",
    "class NextBatchTrainData:\n",
    "    '''\n",
    "    slice small number of data points from the large csr_matrix\n",
    "    make a SparseTensor and return it \n",
    "    '''\n",
    "    def __init__(self, batch_size):\n",
    "        np.random.seed(10)\n",
    "        self.idx = np.arange(0 , data.shape[0])\n",
    "        np.random.shuffle(self.idx)\n",
    "        self.idx = self.idx[:batch_size]\n",
    "        self.current = 0\n",
    "        \n",
    "    def __iter__(self):\n",
    "        return self\n",
    "    \n",
    "    def __next__(self):\n",
    "        if self.current > len(self.idx) -1:\n",
    "            raise StopIteration\n",
    "        else:\n",
    "            self.current += 1\n",
    "            coo_matrix = data[self.current].tocoo()\n",
    "            tf_coo_matrix = tf.SparseTensorValue(\n",
    "                indices=np.array([coo_matrix.row, coo_matrix.col]).T,\n",
    "                values=coo_matrix.data,\n",
    "                dense_shape=coo_matrix.shape)\n",
    "\n",
    "            return tf.SparseTensor.from_value(tf_coo_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # return SparseTensorValue\n",
    "# class NextBatchTrainData:\n",
    "#     '''\n",
    "#     slice small number of data points from the large csr_matrix\n",
    "#     make a SparseTensorValue and return it \n",
    "#     '''\n",
    "#     def __init__(self, batch_size):\n",
    "#         pdb.set_trace()\n",
    "#         np.random.seed(10)\n",
    "#         self.idx = np.arange(0 , data.shape[0])\n",
    "#         np.random.shuffle(self.idx)\n",
    "#         self.idx = self.idx[:batch_size]\n",
    "#         self.current = 0\n",
    "        \n",
    "#     def __iter__(self):\n",
    "#         return self\n",
    "    \n",
    "#     def __next__(self):\n",
    "#         if self.current > len(self.idx) -1:\n",
    "#             raise StopIteration\n",
    "#         else:\n",
    "#             self.current += 1\n",
    "#             coo_matrix = data[self.idx].tocoo()\n",
    "#             return tf.SparseTensorValue(\n",
    "#                 indices=np.array([coo_matrix.row, coo_matrix.col]).T,\n",
    "#                 values=coo_matrix.data,\n",
    "#                 dense_shape=coo_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coo_matrix = data[:100].tocoo()\n",
    "TrainData = tf.SparseTensorValue(\n",
    "    indices=np.array([coo_matrix.row, coo_matrix.col]).T,\n",
    "    values=coo_matrix.data,\n",
    "    dense_shape=coo_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coo_matrix = test[:100].tocoo()\n",
    "TestData = tf.SparseTensorValue(\n",
    "    indices=np.array([coo_matrix.row, coo_matrix.col]).T,\n",
    "    values=coo_matrix.data,\n",
    "    dense_shape=coo_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "C = NextBatchTrainData(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(TrainData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TrainData.dense_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in TrainData:\n",
    "    print(i)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TrainData.values[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.data[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.indices[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TrainData.indices[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "denseTrain = tf.sparse_tensor_to_dense(TrainData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### prepare the test tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "class NextBatchTestData:\n",
    "    def __init__(self, batch_size):\n",
    "        np.random.seed(10)\n",
    "        self.idx = np.arange(0 , test.shape[0])\n",
    "        np.random.shuffle(self.idx)\n",
    "        self.idx = self.idx[:batch_size]\n",
    "        self.current = 0\n",
    "    \n",
    "    def __iter__(self):\n",
    "        return self\n",
    "    \n",
    "    def __next__(self):\n",
    "        if self.current > len(self.idx) -1 :\n",
    "            raise StopIteration\n",
    "        else:\n",
    "            self.current += 1\n",
    "            test_coo_matrix = test[self.current].tocoo()\n",
    "            test_tf_coo_matrix = tf.SparseTensorValue(\n",
    "                indices=np.array([test_coo_matrix.row, test_coo_matrix.col]).T,\n",
    "                values=test_coo_matrix.data,\n",
    "                dense_shape=test_coo_matrix.shape)\n",
    "\n",
    "            return tf.SparseTensor.from_value(test_tf_coo_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The out_values needs to support iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in NextBatchTestData(2):\n",
    "    print(i.get_shape())\n",
    "#     pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sp_tensor.get_shape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(test_sp_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config = tf.ConfigProto()\n",
    "# config.gpu_options.allocator_type ='BFC'\n",
    "# config.gpu_options.per_process_gpu_memory_fraction = 0.90"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# debug the fetch of data to sparse_placeholders\n",
    "sess = tf.InteractiveSession() # using InteractiveSession instead of Session to test network in separate cell\n",
    "# sess = tf.Session() \n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)\n",
    "train_writer = tf.summary.FileWriter(logs_path, sess.graph)\n",
    "batch_x = NextBatchTrainData(batch_size)\n",
    "sess.run([NextBatchTrainData(batch_size)], feed_dict={x_original: batch_x\n",
    "                                                     })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Launch the graph (session)\n",
    "sess = tf.InteractiveSession() # using InteractiveSession instead of Session to test network in separate cell\n",
    "# sess = tf.Session() \n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)\n",
    "train_writer = tf.summary.FileWriter(logs_path, sess.graph)\n",
    "num_tr_iter = int(data.shape[0] / batch_size)\n",
    "global_step = 0\n",
    "for epoch in range(epochs):\n",
    "    print('Training epoch: {}'.format(epoch + 1))\n",
    "    for iteration in range(num_tr_iter):\n",
    "        batch_x = NextBatchTrainData(batch_size)\n",
    "        batch_out = NextBatchTestData(batch_size)\n",
    "#         print(batch_x.get_shape(), flush=True)\n",
    "#         batch_x_noisy = batch_x + noise_level * np.random.normal(loc=0.0, scale=1.0, size=batch_x.shape)\n",
    "\n",
    "        global_step += 1\n",
    "        print(global_step, flush=True)\n",
    "        # Run optimization op (backprop)\n",
    "#         feed_dict_batch = {x_original: batch_x, x_noisy: batch_x_noisy}\n",
    "        feed_dict_batch = {x_original: denseTrain, out_values: TestData} #problem 1\n",
    "        _, summary_tr = sess.run([optimizer, loss], feed_dict=feed_dict_batch)\n",
    "#         feed_dict_batch = {x_original: data[:batch_size]} # just run the optimizer\n",
    "#         opti_result = sess.run([optimizer], feed_dict=feed_dict_batch)\n",
    "        sess.run(optimizer)\n",
    "        \n",
    "        train_writer.add_summary(summary_tr, global_step)\n",
    "\n",
    "        if iteration % display_freq == 0:\n",
    "            # Calculate and display the batch loss and accuracy\n",
    "            loss_batch = sess.run(loss,\n",
    "                                  feed_dict=feed_dict_batch)\n",
    "            print(\"iter {0:3d}:\\t Reconstruction loss={1:.3f}\".\n",
    "                  format(iteration, loss_batch))\n",
    "\n",
    "    # Run validation after every epoch\n",
    "#     x_valid_original  = mnist.validation.images\n",
    "    x_valid_original  = test_sp_tensor\n",
    "#     x_valid_noisy = x_valid_original + noise_level * np.random.normal(loc=0.0, scale=1.0, size=x_valid_original.shape)\n",
    "\n",
    "    feed_dict_valid = {x_original: x_valid_original}\n",
    "    loss_valid = sess.run(loss, feed_dict=feed_dict_valid)\n",
    "    print('---------------------------------------------------------')\n",
    "    print(\"Epoch: {0}, validation loss: {1:.3f}\".\n",
    "          format(epoch + 1, loss_valid))\n",
    "    print('---------------------------------------------------------')\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
