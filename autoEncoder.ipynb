{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# using http://www.easy-tensorflow.com/autoencoders/noise-removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/aymericdamien/TensorFlow-Examples/blob/master/notebooks/3_NeuralNetworks/autoencoder.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Currently Loaded Modulefiles:\r\n",
      "  1) cuda-toolkit/9.0.176   2) cuDNN/9.0v7\r\n"
     ]
    }
   ],
   "source": [
    "!module list "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/esadrfa/libs/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy.sparse as ss\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "featurePath = '/scratch2/esadrfa/perceptron/data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "# csr_mat = pickle.load(open(featurePath + 'SO_CS_EU_Transposed_scaled_s0_e99999_csr.p', 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### I saved the transposed matrix for better performance on SVD but now I am using autoencoder.\n",
    "#### Hence, I have to transpose it again to get each data point as a row "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# csr_mat_100k_23M = csr_mat.transpose()\n",
    "\n",
    "# csr_mat_100k_23M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chunk_size = 20000\n",
    "# for i in range(5):\n",
    "#     s = chunk_size * i\n",
    "#     small_mat = csr_mat_100k_23M[s: s + chunk_size]\n",
    "#     print(s, s + chunk_size)\n",
    "#     pickle.dump(small_mat, open(featurePath \\\n",
    "#                      + 'SO_CS_EU_scaled_s0_e99999_csr_part'+ str(i) +'.p', 'wb'), protocol=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.97 s, sys: 7.84 s, total: 10.8 s\n",
      "Wall time: 10.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train = pickle.load(open(featurePath + 'SO_CS_EU_scaled_s0_e99999_csr_part'+ '4' +'.p', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 20.6 s, sys: 3.62 s, total: 24.2 s\n",
      "Wall time: 24.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "data = train.tocsr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "scipy.sparse.csr.csr_matrix"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(type(data)!='scipy.sparse.csr.csr_matrix'), \"the matrix is not csr\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.46 s, sys: 9.03 s, total: 12.5 s\n",
      "Wall time: 12.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "test = pickle.load(open(featurePath + 'SO_CS_EU_scaled_s0_e99999_csr_part'+ '3' +'.p', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 23 s, sys: 4.12 s, total: 27.1 s\n",
      "Wall time: 27.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "test = test.tocsr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(type(test)!='scipy.sparse.csr.csr_matrix'), \"the matrix is not csr\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_batch_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# coo_matrix = A[:load_batch_size].tocoo()\n",
    "# print('number of rows:' ,coo_matrix.row)\n",
    "\n",
    "# tf_coo_matrix = tf.SparseTensorValue(\n",
    "#     indices=np.array([coo_matrix.row, coo_matrix.col]).T,\n",
    "#     values=coo_matrix.data,\n",
    "#     dense_shape=coo_matrix.shape)\n",
    "\n",
    "# print('type:', type(tf_coo_matrix), '\\nshape:', tf_coo_matrix.dense_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyper-parameters\n",
    "logs_path = \"./logs/noiseRemoval_test_csr_matrix\"  # path to the folder that we want to save the logs for Tensorboard\n",
    "learning_rate = 0.001  # The optimization learning rate\n",
    "epochs = 10  # Total number of training epochs\n",
    "batch_size = 100  # Training batch size\n",
    "display_freq = 100  # Frequency of displaying the training results\n",
    "\n",
    "# Network Parameters\n",
    "# We know that MNIST images are 28 pixels in each dimension.\n",
    "# img_h = img_w = 100\n",
    "num_features = data.shape[1]\n",
    "\n",
    "# Images are stored in one-dimensional arrays of this length.\n",
    "# img_size_flat = img_h * img_w\n",
    "\n",
    "# number of units in the hidden layer\n",
    "h1 = 1000\n",
    "\n",
    "# level of the noise in noisy data\n",
    "# noise_level = 0.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23058100\n"
     ]
    }
   ],
   "source": [
    "print(num_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# weight and bais wrappers\n",
    "def weight_variable(name, shape):\n",
    "    \"\"\"\n",
    "    Create a weight variable with appropriate initialization\n",
    "    :param name: weight name\n",
    "    :param shape: weight shape\n",
    "    :return: initialized weight variable\n",
    "    \"\"\"\n",
    "    initer = tf.truncated_normal_initializer(stddev=0.01)\n",
    "    return tf.get_variable('W_' + name,\n",
    "                           dtype=tf.float32,\n",
    "                           shape=shape,\n",
    "                           initializer=initer)\n",
    "\n",
    "def bias_variable(name, shape):\n",
    "    \"\"\"\n",
    "    Create a bias variable with appropriate initialization\n",
    "    :param name: bias variable name\n",
    "    :param shape: bias variable shape\n",
    "    :return: initialized bias variable\n",
    "    \"\"\"\n",
    "    initial = tf.constant(0., shape=shape, dtype=tf.float32)\n",
    "    return tf.get_variable('b_' + name,\n",
    "                           dtype=tf.float32,\n",
    "                           initializer=initial)\n",
    "\n",
    "def fc_layer(x, num_units, name, use_relu=True):\n",
    "    \"\"\"\n",
    "    Create a fully-connected layer\n",
    "    :param x: input from previous layer\n",
    "    :param num_units: number of hidden units in the fully-connected layer\n",
    "    :param name: layer name\n",
    "    :param use_relu: boolean to add ReLU non-linearity (or not)\n",
    "    :return: The output array\n",
    "    \"\"\"\n",
    "    with tf.variable_scope(name):\n",
    "        in_dim = x.get_shape()[1]\n",
    "        W = weight_variable(name, shape=[in_dim, num_units])\n",
    "        tf.summary.histogram('W', W)\n",
    "        b = bias_variable(name, [num_units])\n",
    "        tf.summary.histogram('b', b)\n",
    "        layer = tf.matmul(x, W)\n",
    "        layer += b\n",
    "        if use_relu:\n",
    "            layer = tf.nn.relu(layer)\n",
    "        return layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### convert the SparseTensorValue to SparseTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# # tf_coo_matrix\n",
    "# st_matrix = tf.SparseTensor.from_value(tf_coo_matrix)\n",
    "# # print(type(st_matrix))\n",
    "# # curr_dense_matrix = tf.sparse_tensor_to_dense(st_matrix)\n",
    "# # type(curr_dense_matrix)\n",
    "# # curr_dense_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import math\n",
    "# num_train = math.floor(tf_coo_matrix.dense_shape[0]*.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create graph\n",
    "# Placeholders for inputs (x), outputs(y)\n",
    "with tf.variable_scope('Input'):\n",
    "    x_original = tf.placeholder(tf.float32, shape=[None, num_features], name='X_original')\n",
    "#     x_noisy = tf.placeholder(tf.float32, shape=[None, num_features], name='X_noisy')\n",
    "\n",
    "# fc1 = fc_layer(x_noisy, h1, 'Hidden_layer', use_relu=True)\n",
    "fc1 = fc_layer(x_original, h1, 'Hidden_layer', use_relu=True)\n",
    "out = fc_layer(fc1, num_features, 'Output_layer', use_relu=False)\n",
    "\n",
    "# Define the loss function, optimizer, and accuracy\n",
    "with tf.variable_scope('Train'):\n",
    "    with tf.variable_scope('Loss'):\n",
    "        loss = tf.reduce_mean(tf.losses.mean_squared_error(x_original, out), name='loss')\n",
    "        tf.summary.scalar('loss', loss)\n",
    "    with tf.variable_scope('Optimizer'):\n",
    "        optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate, name='Adam-op').minimize(loss)\n",
    "\n",
    "# Initializing the variables\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # https://stackoverflow.com/a/40995666/2674061\n",
    "    \n",
    "# def next_batch(num, data):\n",
    "#     '''\n",
    "#     Return a total of `num` random samples\n",
    "#     '''\n",
    "#     idx = np.arange(0 , data.shape[0])\n",
    "#     np.random.shuffle(idx)\n",
    "#     idx = idx[:num]\n",
    "# #     return data[idx].todense()\n",
    "#     return data[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/a/40995666/2674061\n",
    "def next_batch_data(batch_size):\n",
    "    '''\n",
    "    slice small number of data points from the large csr_matrix\n",
    "    make a SparseTensor and return it \n",
    "    '''\n",
    "    idx = np.arange(0 , data.shape[0])\n",
    "    np.random.shuffle(idx)\n",
    "    idx = idx[:batch_size]\n",
    "\n",
    "    coo_matrix = data[idx].tocoo()\n",
    "    tf_coo_matrix = tf.SparseTensorValue(\n",
    "        indices=np.array([coo_matrix.row, coo_matrix.col]).T,\n",
    "        values=coo_matrix.data,\n",
    "        dense_shape=coo_matrix.shape)\n",
    "    \n",
    "    return tf.SparseTensor.from_value(tf_coo_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 53.8 ms, sys: 75.8 ms, total: 130 ms\n",
      "Wall time: 129 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "C = next_batch_data(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.python.framework.sparse_tensor.SparseTensor"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(5), Dimension(23058100)])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C.get_shape()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I need to skip the noise. The noise in general should have the chance to add values to zero elements as well. It is noise afterall and just adding it to the non-zero elements is not real!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### prepare the test tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.08 s, sys: 2.34 s, total: 4.42 s\n",
      "Wall time: 4.43 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "np.random.seed(10)\n",
    "idx = np.arange(0 , test.shape[0])\n",
    "np.random.shuffle(idx)\n",
    "idx = idx[:200]\n",
    "\n",
    "test_coo_matrix = test[idx].tocoo()\n",
    "test_tf_coo_matrix = tf.SparseTensorValue(\n",
    "    indices=np.array([test_coo_matrix.row, test_coo_matrix.col]).T,\n",
    "    values=test_coo_matrix.data,\n",
    "    dense_shape=test_coo_matrix.shape)\n",
    "\n",
    "test_sp_tensor = tf.SparseTensor.from_value(test_tf_coo_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(200), Dimension(23058100)])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sp_tensor.get_shape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "Cannot parse tensor from proto: dtype: DT_FLOAT\ntensor_shape {\n  dim {\n    size: 23058100\n  }\n  dim {\n    size: 1000\n  }\n}\nfloat_val: 0\n\n\t [[Node: Train/Optimizer/Hidden_layer/W_Hidden_layer/Adam-op/Initializer/zeros = Const[dtype=DT_FLOAT, value=Tensor<type: float shape: [23058100,1000] values: [0 0 0]...>, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]()]]\n\nCaused by op 'Train/Optimizer/Hidden_layer/W_Hidden_layer/Adam-op/Initializer/zeros', defined at:\n  File \"/home/esadrfa/libs/anaconda3/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/esadrfa/libs/anaconda3/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/esadrfa/libs/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/esadrfa/libs/anaconda3/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/esadrfa/libs/anaconda3/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 478, in start\n    self.io_loop.start()\n  File \"/home/esadrfa/libs/anaconda3/lib/python3.6/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/home/esadrfa/libs/anaconda3/lib/python3.6/site-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/home/esadrfa/libs/anaconda3/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/esadrfa/libs/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/home/esadrfa/libs/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/esadrfa/libs/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/esadrfa/libs/anaconda3/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/esadrfa/libs/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/esadrfa/libs/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/esadrfa/libs/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/esadrfa/libs/anaconda3/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/esadrfa/libs/anaconda3/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/esadrfa/libs/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2728, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/esadrfa/libs/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2850, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/esadrfa/libs/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2910, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-15-c8f6b7aab744>\", line 17, in <module>\n    optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate, name='Adam-op').minimize(loss)\n  File \"/home/esadrfa/libs/anaconda3/lib/python3.6/site-packages/tensorflow/python/training/optimizer.py\", line 409, in minimize\n    name=name)\n  File \"/home/esadrfa/libs/anaconda3/lib/python3.6/site-packages/tensorflow/python/training/optimizer.py\", line 552, in apply_gradients\n    self._create_slots([_get_variable_for(v) for v in var_list])\n  File \"/home/esadrfa/libs/anaconda3/lib/python3.6/site-packages/tensorflow/python/training/adam.py\", line 131, in _create_slots\n    self._zeros_slot(v, \"m\", self._name)\n  File \"/home/esadrfa/libs/anaconda3/lib/python3.6/site-packages/tensorflow/python/training/optimizer.py\", line 984, in _zeros_slot\n    new_slot_variable = slot_creator.create_zeros_slot(var, op_name)\n  File \"/home/esadrfa/libs/anaconda3/lib/python3.6/site-packages/tensorflow/python/training/slot_creator.py\", line 179, in create_zeros_slot\n    colocate_with_primary=colocate_with_primary)\n  File \"/home/esadrfa/libs/anaconda3/lib/python3.6/site-packages/tensorflow/python/training/slot_creator.py\", line 153, in create_slot_with_initializer\n    dtype)\n  File \"/home/esadrfa/libs/anaconda3/lib/python3.6/site-packages/tensorflow/python/training/slot_creator.py\", line 65, in _create_slot_var\n    validate_shape=validate_shape)\n  File \"/home/esadrfa/libs/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\", line 1297, in get_variable\n    constraint=constraint)\n  File \"/home/esadrfa/libs/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\", line 1093, in get_variable\n    constraint=constraint)\n  File \"/home/esadrfa/libs/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\", line 439, in get_variable\n    constraint=constraint)\n  File \"/home/esadrfa/libs/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\", line 408, in _true_getter\n    use_resource=use_resource, constraint=constraint)\n  File \"/home/esadrfa/libs/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\", line 800, in _get_single_variable\n    use_resource=use_resource)\n  File \"/home/esadrfa/libs/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\", line 2157, in variable\n    use_resource=use_resource)\n  File \"/home/esadrfa/libs/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\", line 2147, in <lambda>\n    previous_getter = lambda **kwargs: default_variable_creator(None, **kwargs)\n  File \"/home/esadrfa/libs/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\", line 2130, in default_variable_creator\n    constraint=constraint)\n  File \"/home/esadrfa/libs/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/variables.py\", line 235, in __init__\n    constraint=constraint)\n  File \"/home/esadrfa/libs/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/variables.py\", line 337, in _init_from_args\n    initial_value(), name=\"initial_value\", dtype=dtype)\n  File \"/home/esadrfa/libs/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\", line 784, in <lambda>\n    shape.as_list(), dtype=dtype, partition_info=partition_info)\n  File \"/home/esadrfa/libs/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py\", line 99, in __call__\n    return array_ops.zeros(shape, dtype)\n  File \"/home/esadrfa/libs/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/array_ops.py\", line 1601, in zeros\n    output = fill(shape, constant(zero, dtype=dtype), name=name)\n  File \"/home/esadrfa/libs/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 2583, in fill\n    \"Fill\", dims=dims, value=value, name=name)\n  File \"/home/esadrfa/libs/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/home/esadrfa/libs/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3290, in create_op\n    op_def=op_def)\n  File \"/home/esadrfa/libs/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1654, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nInvalidArgumentError (see above for traceback): Cannot parse tensor from proto: dtype: DT_FLOAT\ntensor_shape {\n  dim {\n    size: 23058100\n  }\n  dim {\n    size: 1000\n  }\n}\nfloat_val: 0\n\n\t [[Node: Train/Optimizer/Hidden_layer/W_Hidden_layer/Adam-op/Initializer/zeros = Const[dtype=DT_FLOAT, value=Tensor<type: float shape: [23058100,1000] values: [0 0 0]...>, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]()]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m~/libs/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1327\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1328\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/libs/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1311\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1312\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/libs/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1419\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1420\u001b[0;31m             status, run_metadata)\n\u001b[0m\u001b[1;32m   1421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/libs/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[1;32m    515\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 516\u001b[0;31m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[1;32m    517\u001b[0m     \u001b[0;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Cannot parse tensor from proto: dtype: DT_FLOAT\ntensor_shape {\n  dim {\n    size: 23058100\n  }\n  dim {\n    size: 1000\n  }\n}\nfloat_val: 0\n\n\t [[Node: Train/Optimizer/Hidden_layer/W_Hidden_layer/Adam-op/Initializer/zeros = Const[dtype=DT_FLOAT, value=Tensor<type: float shape: [23058100,1000] values: [0 0 0]...>, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]()]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-57f5a9ee1229>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# sess = tf.InteractiveSession() # using InteractiveSession instead of Session to test network in separate cell\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0msess\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# using InteractiveSession instead of Session to test network in separate cell\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mtrain_writer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFileWriter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mnum_tr_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_train\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/libs/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    903\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    904\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 905\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    906\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/libs/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1138\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1139\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1140\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1141\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1142\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/libs/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1319\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1321\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1322\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1323\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/libs/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1338\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1339\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1340\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1342\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Cannot parse tensor from proto: dtype: DT_FLOAT\ntensor_shape {\n  dim {\n    size: 23058100\n  }\n  dim {\n    size: 1000\n  }\n}\nfloat_val: 0\n\n\t [[Node: Train/Optimizer/Hidden_layer/W_Hidden_layer/Adam-op/Initializer/zeros = Const[dtype=DT_FLOAT, value=Tensor<type: float shape: [23058100,1000] values: [0 0 0]...>, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]()]]\n\nCaused by op 'Train/Optimizer/Hidden_layer/W_Hidden_layer/Adam-op/Initializer/zeros', defined at:\n  File \"/home/esadrfa/libs/anaconda3/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/esadrfa/libs/anaconda3/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/esadrfa/libs/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/esadrfa/libs/anaconda3/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/esadrfa/libs/anaconda3/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 478, in start\n    self.io_loop.start()\n  File \"/home/esadrfa/libs/anaconda3/lib/python3.6/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/home/esadrfa/libs/anaconda3/lib/python3.6/site-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/home/esadrfa/libs/anaconda3/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/esadrfa/libs/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/home/esadrfa/libs/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/esadrfa/libs/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/esadrfa/libs/anaconda3/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/esadrfa/libs/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/esadrfa/libs/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/esadrfa/libs/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/esadrfa/libs/anaconda3/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/esadrfa/libs/anaconda3/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/esadrfa/libs/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2728, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/esadrfa/libs/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2850, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/esadrfa/libs/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2910, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-15-c8f6b7aab744>\", line 17, in <module>\n    optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate, name='Adam-op').minimize(loss)\n  File \"/home/esadrfa/libs/anaconda3/lib/python3.6/site-packages/tensorflow/python/training/optimizer.py\", line 409, in minimize\n    name=name)\n  File \"/home/esadrfa/libs/anaconda3/lib/python3.6/site-packages/tensorflow/python/training/optimizer.py\", line 552, in apply_gradients\n    self._create_slots([_get_variable_for(v) for v in var_list])\n  File \"/home/esadrfa/libs/anaconda3/lib/python3.6/site-packages/tensorflow/python/training/adam.py\", line 131, in _create_slots\n    self._zeros_slot(v, \"m\", self._name)\n  File \"/home/esadrfa/libs/anaconda3/lib/python3.6/site-packages/tensorflow/python/training/optimizer.py\", line 984, in _zeros_slot\n    new_slot_variable = slot_creator.create_zeros_slot(var, op_name)\n  File \"/home/esadrfa/libs/anaconda3/lib/python3.6/site-packages/tensorflow/python/training/slot_creator.py\", line 179, in create_zeros_slot\n    colocate_with_primary=colocate_with_primary)\n  File \"/home/esadrfa/libs/anaconda3/lib/python3.6/site-packages/tensorflow/python/training/slot_creator.py\", line 153, in create_slot_with_initializer\n    dtype)\n  File \"/home/esadrfa/libs/anaconda3/lib/python3.6/site-packages/tensorflow/python/training/slot_creator.py\", line 65, in _create_slot_var\n    validate_shape=validate_shape)\n  File \"/home/esadrfa/libs/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\", line 1297, in get_variable\n    constraint=constraint)\n  File \"/home/esadrfa/libs/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\", line 1093, in get_variable\n    constraint=constraint)\n  File \"/home/esadrfa/libs/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\", line 439, in get_variable\n    constraint=constraint)\n  File \"/home/esadrfa/libs/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\", line 408, in _true_getter\n    use_resource=use_resource, constraint=constraint)\n  File \"/home/esadrfa/libs/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\", line 800, in _get_single_variable\n    use_resource=use_resource)\n  File \"/home/esadrfa/libs/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\", line 2157, in variable\n    use_resource=use_resource)\n  File \"/home/esadrfa/libs/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\", line 2147, in <lambda>\n    previous_getter = lambda **kwargs: default_variable_creator(None, **kwargs)\n  File \"/home/esadrfa/libs/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\", line 2130, in default_variable_creator\n    constraint=constraint)\n  File \"/home/esadrfa/libs/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/variables.py\", line 235, in __init__\n    constraint=constraint)\n  File \"/home/esadrfa/libs/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/variables.py\", line 337, in _init_from_args\n    initial_value(), name=\"initial_value\", dtype=dtype)\n  File \"/home/esadrfa/libs/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\", line 784, in <lambda>\n    shape.as_list(), dtype=dtype, partition_info=partition_info)\n  File \"/home/esadrfa/libs/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py\", line 99, in __call__\n    return array_ops.zeros(shape, dtype)\n  File \"/home/esadrfa/libs/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/array_ops.py\", line 1601, in zeros\n    output = fill(shape, constant(zero, dtype=dtype), name=name)\n  File \"/home/esadrfa/libs/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 2583, in fill\n    \"Fill\", dims=dims, value=value, name=name)\n  File \"/home/esadrfa/libs/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/home/esadrfa/libs/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3290, in create_op\n    op_def=op_def)\n  File \"/home/esadrfa/libs/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1654, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nInvalidArgumentError (see above for traceback): Cannot parse tensor from proto: dtype: DT_FLOAT\ntensor_shape {\n  dim {\n    size: 23058100\n  }\n  dim {\n    size: 1000\n  }\n}\nfloat_val: 0\n\n\t [[Node: Train/Optimizer/Hidden_layer/W_Hidden_layer/Adam-op/Initializer/zeros = Const[dtype=DT_FLOAT, value=Tensor<type: float shape: [23058100,1000] values: [0 0 0]...>, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]()]]\n"
     ]
    }
   ],
   "source": [
    "# Launch the graph (session)\n",
    "# sess = tf.InteractiveSession() # using InteractiveSession instead of Session to test network in separate cell\n",
    "sess = tf.Session() # using InteractiveSession instead of Session to test network in separate cell\n",
    "sess.run(init)\n",
    "train_writer = tf.summary.FileWriter(logs_path, sess.graph)\n",
    "num_tr_iter = int(num_train / batch_size)\n",
    "global_step = 0\n",
    "for epoch in range(epochs):\n",
    "    print('Training epoch: {}'.format(epoch + 1))\n",
    "    for iteration in range(num_tr_iter):\n",
    "        batch_x = next_batch_data(batch_size)\n",
    "        print(batch_x.get_shape())\n",
    "#         batch_x_noisy = batch_x + noise_level * np.random.normal(loc=0.0, scale=1.0, size=batch_x.shape)\n",
    "\n",
    "        global_step += 1\n",
    "        print(global_step)\n",
    "        # Run optimization op (backprop)\n",
    "#         feed_dict_batch = {x_original: batch_x, x_noisy: batch_x_noisy}\n",
    "        feed_dict_batch = {x_original: batch_x}\n",
    "        _, summary_tr = sess.run([optimizer, merged], feed_dict=feed_dict_batch)\n",
    "        train_writer.add_summary(summary_tr, global_step)\n",
    "\n",
    "        if iteration % display_freq == 0:\n",
    "            # Calculate and display the batch loss and accuracy\n",
    "            loss_batch = sess.run(loss,\n",
    "                                  feed_dict=feed_dict_batch)\n",
    "            print(\"iter {0:3d}:\\t Reconstruction loss={1:.3f}\".\n",
    "                  format(iteration, loss_batch))\n",
    "\n",
    "    # Run validation after every epoch\n",
    "#     x_valid_original  = mnist.validation.images\n",
    "    x_valid_original  = test_sp_tensor\n",
    "#     x_valid_noisy = x_valid_original + noise_level * np.random.normal(loc=0.0, scale=1.0, size=x_valid_original.shape)\n",
    "\n",
    "    feed_dict_valid = {x_original: x_valid_original}\n",
    "    loss_valid = sess.run(loss, feed_dict=feed_dict_valid)\n",
    "    print('---------------------------------------------------------')\n",
    "    print(\"Epoch: {0}, validation loss: {1:.3f}\".\n",
    "          format(epoch + 1, loss_valid))\n",
    "    print('---------------------------------------------------------')\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
